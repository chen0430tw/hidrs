input {
  # 处理TXT文件
  file {
    path => "${DATA_PATH:/data}/*.txt"
    start_position => "beginning"
    sincedb_path => "${SINCEDB_PATH_TXT:/dev/null}"
    mode => "read"
    tags => ["txt_format"]
  }
  
  # 处理CSV文件
  file {
    path => "${DATA_PATH:/data}/*.csv"
    start_position => "beginning"
    sincedb_path => "${SINCEDB_PATH_CSV:/dev/null}"
    tags => ["csv_format"]
  }
  
  # 处理LOG文件
  file {
    path => "${DATA_PATH:/data}/*.log"
    start_position => "beginning"
    sincedb_path => "${SINCEDB_PATH_LOG:/dev/null}"
    tags => ["log_format"]
  }
  
  # JDBC输入用于处理已导入到临时数据库的SQL数据
  # 只有在设置了相应环境变量时才启用
  jdbc {
    jdbc_driver_library => "${JDBC_DRIVER_PATH:/usr/share/logstash/mysql-connector-java.jar}"
    jdbc_driver_class => "${JDBC_DRIVER_CLASS:com.mysql.jdbc.Driver}"
    jdbc_connection_string => "${JDBC_URL:jdbc:mysql://localhost:3306/temp_db}"
    jdbc_user => "${DB_USER:root}"
    jdbc_password => "${DB_PASSWORD:}"
    statement => "${SQL_QUERY:SELECT * FROM imported_data}"
    schedule => "${JDBC_SCHEDULE:* * * * *}"
    tags => ["jdbc_source"]
    enabled => "${JDBC_ENABLED:false}"
  }
}

filter {
  # TXT文件处理
  if "txt_format" in [tags] {
    # 尝试匹配email----password格式
    grok {
      match => { "message" => "(?<email>[^-]+)----(?<password>.+)" }
      tag_on_failure => ["grok_email_password_failed"]
    }
    
    # 如果上面的匹配失败，尝试匹配user----password格式
    if "grok_email_password_failed" in [tags] {
      grok {
        match => { "message" => "(?<user>[^-]+)----(?<password>.+)" }
        tag_on_failure => ["grok_user_password_failed"]
      }
    }
    
    # 如果前两种格式都失败，尝试匹配通用格式
    if "grok_user_password_failed" in [tags] {
      grok {
        match => { "message" => "(?<data>.*)" }
        tag_on_failure => ["grok_all_failed"]
      }
    }
  }
  
  # CSV文件处理
  else if "csv_format" in [tags] {
    csv {
      separator => ","
      skip_header => "true"
      columns => ["user", "password", "passwordHash", "email", "source", "xtime"]
      skip_empty_columns => true
    }
  }
  
  # LOG文件处理
  else if "log_format" in [tags] {
    # 尝试匹配常见日志格式中的凭据
    grok {
      match => [
        "message", "(?<timestamp>%{TIMESTAMP_ISO8601})\s+%{WORD:log_level}\s+(?<email>[^\s:]+):(?<password>[^\s]+)",
        "message", "(?<user>[a-zA-Z0-9._-]+):(?<password>[^\s]+)",
        "message", "(?<email>[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})[\s:]+(?<password>[^\s]+)"
      ]
      tag_on_failure => ["grok_log_failed"]
    }
  }
  
  # 从邮箱解析用户名和后缀
  if [email] {
    grok {
      match => { "email" => "(?<user>[^@]+)@(?<suffix_email>.+)" }
    }
  }
  
  # 计算密码哈希值
  if [password] and ![passwordHash] {
    ruby {
      code => "
        require 'digest/md5'
        event.set('passwordHash', Digest::MD5.hexdigest(event.get('password')))
      "
    }
  }
  
  # 添加时间和来源信息
  mutate {
    add_field => {
      "xtime" => "${LEAK_TIME:%{+YYYY.MM}}"
      "source" => "${SOURCE:unknown}"
      "create_time" => "%{+YYYY/MM/dd HH:mm:ss}"
    }
    remove_field => ["@version", "host", "path", "tags"]
  }
}

output {
  # 主要输出到Elasticsearch
  elasticsearch {
    hosts => ["${ES_HOST:localhost}:${ES_PORT:9200}"]
    index => "${ES_INDEX:socialdb}"
    user => "${ES_USER:}"
    password => "${ES_PASSWORD:}"
  }
  
  # 调试输出
  stdout {
    codec => rubydebug
  }
}