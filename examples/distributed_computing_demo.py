#!/usr/bin/env python3
"""
HIDRS åˆ†å¸ƒå¼è®¡ç®—ç³»ç»Ÿæ¼”ç¤º

å±•ç¤ºå¦‚ä½•ä½¿ç”¨HLIGç†è®ºè¿›è¡Œåˆ†å¸ƒå¼è®¡ç®—ï¼š
1. èŠ‚ç‚¹å‘ç°ï¼ˆP2Pï¼‰
2. ç®—åŠ›è¯„ä¼°
3. HLIGä»»åŠ¡è°ƒåº¦ï¼ˆFiedlerå‘é‡ä¼˜åŒ–ï¼‰
4. åˆ†å¸ƒå¼æ‰§è¡Œ
5. ç»“æœèšåˆ

è¿™æ˜¯å…¨çƒå¹¿æ’­ç³»ç»Ÿçš„**é€†å‘åº”ç”¨**ï¼š
- å…¨çƒå¹¿æ’­ = æˆ‘å‘å…¨çƒæ¨é€æ¶ˆæ¯
- åˆ†å¸ƒå¼è®¡ç®— = æˆ‘ä»å…¨çƒæ‹‰å–ç®—åŠ›

ç±»æ¯”ï¼š
- åŒºå—é“¾ + SETI@home + HLIGç†è®º
- å»ä¸­å¿ƒåŒ– + å…¨çƒç®—åŠ›å…±äº« + æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©
"""
import sys
import os
import logging
import time
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from hidrs.distributed_computing import (
    NodeManager,
    ComputeNode,
    NodeStatus,
    CapabilityAnalyzer,
    NodeCapability,
    HLIGTaskScheduler,
    ComputeTask,
    TaskType,
    TaskStatus,
    HLIGLoadBalancer,
    ComputeWorker,
    WorkerStatus,
    ResultAggregator,
    AggregationType
)
from hidrs.distributed_computing.compute_worker import register_example_functions

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def print_separator(title=""):
    """æ‰“å°åˆ†éš”ç¬¦"""
    width = 80
    if title:
        padding = (width - len(title) - 2) // 2
        print("=" * padding + f" {title} " + "=" * padding)
    else:
        print("=" * width)


def demo_node_discovery():
    """æ¼”ç¤º1ï¼šèŠ‚ç‚¹å‘ç°"""
    print_separator("æ¼”ç¤º1: èŠ‚ç‚¹å‘ç°")
    print("\nä½¿ç”¨P2Påè®®å‘ç°ç½‘ç»œä¸­çš„è®¡ç®—èŠ‚ç‚¹ï¼ˆç±»ä¼¼BitTorrent DHTï¼‰")

    # åˆ›å»ºèŠ‚ç‚¹ç®¡ç†å™¨
    node_manager = NodeManager(
        listen_port=9876,
        heartbeat_interval=30,
        enable_lan_discovery=True
    )

    # å¯åŠ¨èŠ‚ç‚¹ç®¡ç†å™¨
    node_manager.start()

    print(f"\nâœ… èŠ‚ç‚¹ç®¡ç†å™¨å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£: 9876")
    print(f"   æ­£åœ¨å‘ç°å±€åŸŸç½‘ä¸­çš„èŠ‚ç‚¹...")

    # æ¨¡æ‹Ÿæ·»åŠ ä¸€äº›èŠ‚ç‚¹ï¼ˆå®é™…ç¯å¢ƒä¸­é€šè¿‡P2På‘ç°ï¼‰
    mock_nodes = [
        ComputeNode(
            node_id=f"node_{i}",
            host=f"192.168.1.{10 + i}",
            port=9876,
            status=NodeStatus.ONLINE,
            cpu_cores=4 + i * 2,
            cpu_freq_mhz=2400 + i * 200,
            memory_gb=8 + i * 4,
            gpu_count=i % 2,
            gpu_memory_gb=(i % 2) * 8
        )
        for i in range(5)
    ]

    for node in mock_nodes:
        node_manager.register_node(node)

    time.sleep(1)

    # æ˜¾ç¤ºå‘ç°çš„èŠ‚ç‚¹
    stats = node_manager.get_stats()
    print(f"\nğŸ“Š èŠ‚ç‚¹å‘ç°å®Œæˆ:")
    print(f"   æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}")
    print(f"   åœ¨çº¿èŠ‚ç‚¹: {stats['online_nodes']}")
    print(f"   æ€»CPUæ ¸å¿ƒæ•°: {stats['total_cpu_cores']}")
    print(f"   æ€»å†…å­˜: {stats['total_memory_gb']:.1f} GB")
    print(f"   æ€»GPUæ•°: {stats['total_gpu_count']}")

    print("\nèŠ‚ç‚¹åˆ—è¡¨:")
    for node in node_manager.get_online_nodes():
        print(f"   [{node.node_id}] {node.host}:{node.port}")
        print(f"      CPU: {node.cpu_cores}æ ¸ @ {node.cpu_freq_mhz:.0f}MHz")
        print(f"      å†…å­˜: {node.memory_gb:.1f}GB")
        print(f"      GPU: {node.gpu_count}ä¸ª")

    return node_manager


def demo_capability_analysis(node_manager):
    """æ¼”ç¤º2ï¼šç®—åŠ›è¯„ä¼°"""
    print_separator("æ¼”ç¤º2: ç®—åŠ›è¯„ä¼°")
    print("\nè¯„ä¼°æ¯ä¸ªèŠ‚ç‚¹çš„ç»¼åˆç®—åŠ›å¾—åˆ†")

    # åˆ›å»ºç®—åŠ›è¯„ä¼°å™¨
    analyzer = CapabilityAnalyzer(
        weight_cpu=0.4,
        weight_gpu=0.3,
        weight_memory=0.2,
        weight_network=0.1
    )

    print(f"\nè¯„åˆ†æƒé‡: CPU={analyzer.weight_cpu:.1f}, GPU={analyzer.weight_gpu:.1f}, "
          f"å†…å­˜={analyzer.weight_memory:.1f}, ç½‘ç»œ={analyzer.weight_network:.1f}")

    # è¯„ä¼°æ‰€æœ‰èŠ‚ç‚¹
    nodes = node_manager.get_online_nodes()
    capabilities = []

    print("\nèŠ‚ç‚¹ç®—åŠ›è¯„åˆ†:")
    for node in nodes:
        # æ¨¡æ‹Ÿè¯„ä¼°ï¼ˆå®é™…åº”è¯¥è°ƒç”¨analyzer.analyze_remote_nodeï¼‰
        cap = NodeCapability(
            cpu_cores=node.cpu_cores,
            cpu_threads=node.cpu_cores * 2,
            cpu_freq_mhz=node.cpu_freq_mhz,
            memory_total_gb=node.memory_gb,
            gpu_count=node.gpu_count,
            gpu_memory_total_gb=node.gpu_memory_gb
        )

        cap.cpu_score = analyzer._compute_cpu_score(cap)
        cap.gpu_score = analyzer._compute_gpu_score(cap)
        cap.memory_score = analyzer._compute_memory_score(cap)
        cap.network_score = 50.0  # ç®€åŒ–

        cap.total_score = (
            analyzer.weight_cpu * cap.cpu_score +
            analyzer.weight_gpu * cap.gpu_score +
            analyzer.weight_memory * cap.memory_score +
            analyzer.weight_network * cap.network_score
        )

        capabilities.append(cap)

        # æ›´æ–°èŠ‚ç‚¹ç®—åŠ›å¾—åˆ†
        node.capability_score = cap.total_score

        print(f"   [{node.node_id}] æ€»åˆ†: {cap.total_score:.2f}/100")
        print(f"      CPU: {cap.cpu_score:.1f}, GPU: {cap.gpu_score:.1f}, "
              f"å†…å­˜: {cap.memory_score:.1f}, ç½‘ç»œ: {cap.network_score:.1f}")

    # æ’å
    ranked = analyzer.rank_nodes(capabilities)
    print(f"\nğŸ† ç®—åŠ›æ’åTop 3:")
    for i, cap in enumerate(ranked[:3], 1):
        print(f"   {i}. èŠ‚ç‚¹ (æ€»åˆ†: {cap.total_score:.2f})")

    return analyzer


def demo_hlig_scheduling(node_manager, analyzer):
    """æ¼”ç¤º3ï¼šHLIGä»»åŠ¡è°ƒåº¦"""
    print_separator("æ¼”ç¤º3: HLIGä»»åŠ¡è°ƒåº¦")
    print("\nä½¿ç”¨Fiedlerå‘é‡è¯†åˆ«å…³é”®èŠ‚ç‚¹å¹¶ä¼˜åŒ–ä»»åŠ¡åˆ†é…")

    # åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨
    scheduler = HLIGTaskScheduler(
        node_manager=node_manager,
        capability_analyzer=analyzer,
        use_fiedler=True
    )

    # æäº¤ä¸€äº›ä»»åŠ¡
    tasks = [
        ComputeTask(
            task_id=f"task_{i}",
            task_type=TaskType.COMPUTE_INTENSIVE if i % 2 == 0 else TaskType.NETWORK_INTENSIVE,
            function_name="monte_carlo_pi",
            args=(1000000,),
            required_cpu_cores=2,
            required_memory_gb=2.0,
            priority=i
        )
        for i in range(10)
    ]

    print(f"\næäº¤ {len(tasks)} ä¸ªä»»åŠ¡:")
    for task in tasks:
        scheduler.submit_task(task)
        print(f"   [{task.task_id}] ç±»å‹: {task.task_type.value}, ä¼˜å…ˆçº§: {task.priority}")

    # æ‰§è¡Œè°ƒåº¦
    print("\nå¼€å§‹HLIGåˆ†æå’Œä»»åŠ¡è°ƒåº¦...")
    assignments = scheduler.schedule_tasks()

    # æ˜¾ç¤ºè°ƒåº¦ç»“æœ
    print(f"\nâœ… è°ƒåº¦å®Œæˆ: {len(assignments)} ä¸ªä»»åŠ¡å·²åˆ†é…")

    # æŒ‰èŠ‚ç‚¹åˆ†ç»„æ˜¾ç¤º
    from collections import defaultdict
    node_tasks = defaultdict(list)
    for task_id, node_id in assignments:
        node_tasks[node_id].append(task_id)

    print("\nä»»åŠ¡åˆ†é…è¯¦æƒ…:")
    for node_id, task_ids in node_tasks.items():
        node = node_manager.get_node(node_id)
        is_key = "â­" if node.is_key_node else "  "
        print(f"   {is_key}[{node_id}] {len(task_ids)} ä¸ªä»»åŠ¡ (Fiedlerå¾—åˆ†: {node.fiedler_score:.4f})")
        for task_id in task_ids:
            print(f"      - {task_id}")

    # æ˜¾ç¤ºç»Ÿè®¡
    stats = scheduler.get_stats()
    print(f"\nğŸ“Š è°ƒåº¦ç»Ÿè®¡:")
    print(f"   æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
    print(f"   å·²è°ƒåº¦: {stats['scheduled_tasks']}")
    print(f"   å¾…è°ƒåº¦: {stats['pending_tasks']}")
    print(f"   Fiedlerå€¼: {stats['fiedler_value']:.6f}")
    print(f"   å…³é”®èŠ‚ç‚¹æ•°: {stats['key_nodes_count']}")

    return scheduler


def demo_load_balancing(node_manager):
    """æ¼”ç¤º4ï¼šè´Ÿè½½å‡è¡¡"""
    print_separator("æ¼”ç¤º4: HLIGè´Ÿè½½å‡è¡¡")
    print("\nåŸºäºæ‹‰æ™®æ‹‰æ–¯æµçš„åŠ¨æ€è´Ÿè½½å‡è¡¡")

    # åˆ›å»ºè´Ÿè½½å‡è¡¡å™¨
    load_balancer = HLIGLoadBalancer(
        node_manager=node_manager,
        rebalance_threshold=0.3,
        enable_migration=True
    )

    # æ¨¡æ‹Ÿä¸å‡è¡¡çš„è´Ÿè½½
    nodes = node_manager.get_online_nodes()
    loads = [0.1, 0.3, 0.9, 0.7, 0.2]  # ä¸å‡è¡¡è´Ÿè½½

    print("\nå½“å‰è´Ÿè½½åˆ†å¸ƒï¼ˆä¸å‡è¡¡ï¼‰:")
    for node, load in zip(nodes, loads):
        load_balancer.update_node_load(node.node_id, load)
        bar = "â–ˆ" * int(load * 20)
        print(f"   [{node.node_id}] {bar} {load * 100:.0f}%")

    # æ£€æŸ¥å‡è¡¡çŠ¶æ€
    balance_status = load_balancer.check_balance()
    print(f"\nå‡è¡¡çŠ¶æ€:")
    print(f"   æœ€å¤§è´Ÿè½½: {balance_status['max_load'] * 100:.0f}%")
    print(f"   æœ€å°è´Ÿè½½: {balance_status['min_load'] * 100:.0f}%")
    print(f"   å¹³å‡è´Ÿè½½: {balance_status['avg_load'] * 100:.0f}%")
    print(f"   ä¸å¹³è¡¡åº¦: {balance_status['imbalance']:.2f}")
    print(f"   éœ€è¦é‡å¹³è¡¡: {'æ˜¯' if balance_status['needs_rebalance'] else 'å¦'}")

    # æ‰§è¡Œé‡å¹³è¡¡
    if balance_status['needs_rebalance']:
        print("\næ‰§è¡Œè´Ÿè½½é‡å¹³è¡¡...")
        rebalance_result = load_balancer.rebalance()

        if rebalance_result['status'] == 'success':
            migrations = rebalance_result['migrations']
            print(f"\nâœ… é‡å¹³è¡¡å®Œæˆï¼Œå»ºè®® {len(migrations)} æ¬¡è¿ç§»:")

            for mig in migrations:
                print(f"   {mig['from_node']} â†’ {mig['to_node']}: {mig['load_amount'] * 100:.1f}%")
                print(f"      (å½“å‰è´Ÿè½½: {mig['from_current_load'] * 100:.0f}% â†’ {mig['to_current_load'] * 100:.0f}%)")

            # æ˜¾ç¤ºç›®æ ‡è´Ÿè½½åˆ†å¸ƒ
            print("\nç›®æ ‡è´Ÿè½½åˆ†å¸ƒï¼ˆå¹³è¡¡åï¼‰:")
            for node, target_load in zip(nodes, rebalance_result['target_loads']):
                bar = "â–ˆ" * int(target_load * 20)
                print(f"   [{node.node_id}] {bar} {target_load * 100:.0f}%")

    return load_balancer


def demo_distributed_execution():
    """æ¼”ç¤º5ï¼šåˆ†å¸ƒå¼æ‰§è¡Œ"""
    print_separator("æ¼”ç¤º5: åˆ†å¸ƒå¼æ‰§è¡Œ")
    print("\næ¨¡æ‹Ÿåˆ†å¸ƒå¼è®¡ç®—Ï€å€¼ï¼ˆè’™ç‰¹å¡æ´›æ–¹æ³•ï¼‰")

    # åˆ›å»ºå·¥ä½œèŠ‚ç‚¹
    workers = []
    for i in range(3):
        worker = ComputeWorker(
            worker_id=f"worker_{i}",
            max_concurrent_tasks=2,
            timeout_seconds=60
        )
        register_example_functions(worker)
        workers.append(worker)

    print(f"\nåˆ›å»ºäº† {len(workers)} ä¸ªå·¥ä½œèŠ‚ç‚¹")

    # åˆ›å»ºä»»åŠ¡
    iterations_per_task = 1000000
    tasks = [
        ComputeTask(
            task_id=f"pi_task_{i}",
            task_type=TaskType.COMPUTE_INTENSIVE,
            function_name="monte_carlo_pi",
            args=(iterations_per_task,),
            required_cpu_cores=1
        )
        for i in range(10)
    ]

    print(f"\nä»»åŠ¡: è®¡ç®—Ï€å€¼ï¼Œæ¯ä¸ªä»»åŠ¡ {iterations_per_task} æ¬¡è¿­ä»£")
    print(f"æ€»å…± {len(tasks)} ä¸ªä»»åŠ¡\n")

    # åˆ†é…ä»»åŠ¡åˆ°å·¥ä½œèŠ‚ç‚¹
    print("åˆ†é…ä»»åŠ¡åˆ°å·¥ä½œèŠ‚ç‚¹...")
    start_time = time.time()

    for i, task in enumerate(tasks):
        worker = workers[i % len(workers)]
        worker.execute_task(task)
        print(f"   ä»»åŠ¡ {task.task_id} â†’ {worker.worker_id}")

    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    print("\nç­‰å¾…ä»»åŠ¡å®Œæˆ...")
    max_wait = 60
    waited = 0
    while waited < max_wait:
        all_done = all(
            w.status in [WorkerStatus.IDLE, WorkerStatus.ERROR]
            for w in workers
        )
        if all_done:
            break
        time.sleep(1)
        waited += 1
        if waited % 5 == 0:
            print(f"   ... {waited}ç§’")

    elapsed = time.time() - start_time

    # æ”¶é›†ç»“æœ
    results = []
    for worker in workers:
        for task_id, task_info in worker.current_tasks.items():
            if task_info['status'] == 'completed':
                results.append({
                    'worker_id': worker.worker_id,
                    'task_id': task_id,
                    'result': task_info['result']
                })

    print(f"\nâœ… æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    print(f"   å®Œæˆ: {len(results)}/{len(tasks)} ä¸ªä»»åŠ¡")

    # æ˜¾ç¤ºå·¥ä½œèŠ‚ç‚¹ç»Ÿè®¡
    print("\nå·¥ä½œèŠ‚ç‚¹ç»Ÿè®¡:")
    for worker in workers:
        stats = worker.get_stats()
        print(f"   [{worker.worker_id}]")
        print(f"      å®Œæˆ: {stats['completed_tasks']}, å¤±è´¥: {stats['failed_tasks']}")
        print(f"      æˆåŠŸç‡: {stats['success_rate'] * 100:.1f}%")

    return results


def demo_result_aggregation(results):
    """æ¼”ç¤º6ï¼šç»“æœèšåˆ"""
    print_separator("æ¼”ç¤º6: ç»“æœèšåˆ")
    print("\nèšåˆåˆ†å¸ƒå¼è®¡ç®—ç»“æœ")

    # åˆ›å»ºç»“æœèšåˆå™¨
    aggregator = ResultAggregator(use_hlig_weighting=True)

    # å‡†å¤‡ç»“æœæ•°æ®
    result_data = [
        {'node_id': r['worker_id'], 'result': r['result']}
        for r in results
    ]

    print(f"\næ”¶é›†åˆ° {len(result_data)} ä¸ªç»“æœ")
    print("\nå„èŠ‚ç‚¹è®¡ç®—çš„Ï€å€¼:")
    for r in result_data[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"   {r['node_id']}: Ï€ â‰ˆ {r['result']:.6f}")
    if len(result_data) > 5:
        print(f"   ... (è¿˜æœ‰ {len(result_data) - 5} ä¸ª)")

    # æ ‡å‡†èšåˆï¼ˆå¹³å‡å€¼ï¼‰
    pi_average = aggregator.aggregate(
        result_data,
        aggregation_type=AggregationType.AVERAGE
    )

    print(f"\nğŸ“Š èšåˆç»“æœ:")
    print(f"   å¹³å‡å€¼: Ï€ â‰ˆ {pi_average:.6f}")
    print(f"   çœŸå®å€¼: Ï€ = {np.pi:.6f}")
    print(f"   è¯¯å·®: {abs(pi_average - np.pi):.6f}")

    # æ¨¡æ‹ŸHLIGåŠ æƒèšåˆ
    node_weights = {
        f"worker_{i}": 1.0 + i * 0.1  # æ¨¡æ‹ŸFiedleræƒé‡
        for i in range(3)
    }

    pi_weighted = aggregator.aggregate(
        result_data,
        aggregation_type=AggregationType.AVERAGE,
        node_weights=node_weights
    )

    print(f"\nä½¿ç”¨HLIGæƒé‡èšåˆ:")
    print(f"   åŠ æƒå¹³å‡: Ï€ â‰ˆ {pi_weighted:.6f}")
    print(f"   è¯¯å·®: {abs(pi_weighted - np.pi):.6f}")


def demo_comparison():
    """æ¼”ç¤º7ï¼šä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”"""
    print_separator("æ¼”ç¤º7: ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”")
    print("\nå¯¹æ¯”HIDRSä¸ä¼ ç»Ÿåˆ†å¸ƒå¼è®¡ç®—")

    comparison = """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ç‰¹æ€§               â”‚ HIDRS (HLIG)        â”‚ ä¼ ç»Ÿæ–¹æ³•            â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ èŠ‚ç‚¹å‘ç°           â”‚ P2På»ä¸­å¿ƒåŒ–          â”‚ ä¸­å¿ƒåŒ–æ³¨å†Œ          â”‚
    â”‚ ä»»åŠ¡è°ƒåº¦           â”‚ Fiedlerå‘é‡ä¼˜åŒ–      â”‚ è½®è¯¢/éšæœº           â”‚
    â”‚ èŠ‚ç‚¹é€‰æ‹©           â”‚ è¯†åˆ«å…³é”®èŠ‚ç‚¹ä¼˜å…ˆ     â”‚ æœºæ¢°å¹³å‡åˆ†é…        â”‚
    â”‚ è´Ÿè½½å‡è¡¡           â”‚ æ‹‰æ™®æ‹‰æ–¯æµ           â”‚ è´ªå¿ƒç®—æ³•            â”‚
    â”‚ ç»“æœèšåˆ           â”‚ å…¨æ¯æ˜ å°„åŠ æƒ         â”‚ ç®€å•å¹³å‡            â”‚
    â”‚ ç½‘ç»œæ‹“æ‰‘æ„ŸçŸ¥       â”‚ æ˜¯ï¼ˆæ‹‰æ™®æ‹‰æ–¯çŸ©é˜µï¼‰   â”‚ å¦                  â”‚
    â”‚ é€‚åº”æ€§             â”‚ åŠ¨æ€ä¼˜åŒ–             â”‚ é™æ€é…ç½®            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    æ ¸å¿ƒä¼˜åŠ¿ï¼š
    âœ… æ™ºèƒ½è¯†åˆ«"è¶…çº§èŠ‚ç‚¹"ï¼ˆFiedlerå‘é‡ï¼‰
    âœ… å…¨å±€æœ€ä¼˜ä»»åŠ¡åˆ†é…ï¼ˆè°±åˆ†æï¼‰
    âœ… è‡ªé€‚åº”è´Ÿè½½å‡è¡¡ï¼ˆæ‹‰æ™®æ‹‰æ–¯æµï¼‰
    âœ… å»ä¸­å¿ƒåŒ–æ¶æ„ï¼ˆP2Pï¼‰

    ç±»æ¯”ï¼š
    - ä¼ ç»Ÿæ–¹æ³• = ç›²äººæ‘¸è±¡ï¼Œå±€éƒ¨ä¼˜åŒ–
    - HIDRS = å…¨æ¯è§†è§’ï¼Œå…¨å±€æœ€ä¼˜
    """

    print(comparison)


def main():
    """ä¸»å‡½æ•°"""
    print_separator("HIDRS åˆ†å¸ƒå¼è®¡ç®—ç³»ç»Ÿæ¼”ç¤º")
    print("\nå…¨çƒå¹¿æ’­ç³»ç»Ÿçš„é€†å‘åº”ç”¨ï¼šè·Ÿå…¨çƒå€Ÿç®—åŠ›")
    print("\næ ¸å¿ƒç†å¿µ:")
    print("  å…¨çƒå¹¿æ’­ = æˆ‘å‘å…¨çƒæ¨é€æ¶ˆæ¯")
    print("  åˆ†å¸ƒå¼è®¡ç®— = æˆ‘ä»å…¨çƒæ‹‰å–ç®—åŠ›")
    print("\nè¿™æ˜¯: åŒºå—é“¾ + SETI@home + HLIGç†è®º")
    print("  - åŒºå—é“¾: P2På»ä¸­å¿ƒåŒ–ç½‘ç»œ")
    print("  - SETI@home: å…¨çƒç®—åŠ›å…±äº«")
    print("  - HLIG: æ™ºèƒ½èŠ‚ç‚¹é€‰æ‹©ï¼ˆFiedlerå‘é‡ï¼‰")

    try:
        input("\næŒ‰Enteré”®å¼€å§‹æ¼”ç¤º...")

        # 1. èŠ‚ç‚¹å‘ç°
        node_manager = demo_node_discovery()
        input("\næŒ‰Enteré”®ç»§ç»­...")

        # 2. ç®—åŠ›è¯„ä¼°
        analyzer = demo_capability_analysis(node_manager)
        input("\næŒ‰Enteré”®ç»§ç»­...")

        # 3. HLIGä»»åŠ¡è°ƒåº¦
        scheduler = demo_hlig_scheduling(node_manager, analyzer)
        input("\næŒ‰Enteré”®ç»§ç»­...")

        # 4. è´Ÿè½½å‡è¡¡
        load_balancer = demo_load_balancing(node_manager)
        input("\næŒ‰Enteré”®ç»§ç»­...")

        # 5. åˆ†å¸ƒå¼æ‰§è¡Œ
        results = demo_distributed_execution()
        input("\næŒ‰Enteré”®ç»§ç»­...")

        # 6. ç»“æœèšåˆ
        demo_result_aggregation(results)
        input("\næŒ‰Enteré”®ç»§ç»­...")

        # 7. å¯¹æ¯”
        demo_comparison()

        print_separator("æ¼”ç¤ºå®Œæˆ")
        print("\næ€»ç»“:")
        print("  âœ… HIDRSåˆ†å¸ƒå¼è®¡ç®—ç³»ç»Ÿå±•ç¤ºäº†HLIGç†è®ºåœ¨åˆ†å¸ƒå¼è®¡ç®—ä¸­çš„åº”ç”¨")
        print("  âœ… Fiedlerå‘é‡æˆåŠŸè¯†åˆ«äº†ç½‘ç»œä¸­çš„å…³é”®èŠ‚ç‚¹")
        print("  âœ… æ‹‰æ™®æ‹‰æ–¯è°±åˆ†æå®ç°äº†å…¨å±€æœ€ä¼˜ä»»åŠ¡åˆ†é…")
        print("  âœ… è¿™æ˜¯å…¨çƒå¹¿æ’­ç³»ç»Ÿçš„å®Œç¾é€†å‘åº”ç”¨")

        # åœæ­¢èŠ‚ç‚¹ç®¡ç†å™¨
        node_manager.stop()

    except KeyboardInterrupt:
        print("\n\næ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}", exc_info=True)


if __name__ == "__main__":
    main()
